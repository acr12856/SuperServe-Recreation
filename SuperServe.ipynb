{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088293fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb444ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated LayerSelect. We can choose whether we want a layer to be active\n",
    "# or not by toggling the active parameter. \n",
    "class LayerSelect(nn.Module):\n",
    "    def __init__(self, layer, active=True):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.active = active\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.active:\n",
    "            return self.layer(x)\n",
    "        else:\n",
    "            return x  # Skip layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27b09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated SubnetNorm\n",
    "class SubnetNorm2d(nn.Module):\n",
    "    def __init__(self, num_channels, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "        self.stats = {}  # config_id -> {\"mean\": tensor, \"var\": tensor}\n",
    "        self.active_config = None\n",
    "\n",
    "    def set_active(self, config_id):\n",
    "        self.active_config = config_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.active_config in self.stats:\n",
    "            stats = self.stats[self.active_config]\n",
    "            C = x.shape[1]\n",
    "            mean = stats[\"mean\"][:C]\n",
    "            var = stats[\"var\"][:C]\n",
    "            x_hat = (x - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "            return x_hat\n",
    "        else:\n",
    "            # If no stats yet, just pass through identity (or use dummy BatchNorm if needed)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26abafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated ResNet blocks. Has a convolution layer followed by a batchnorm layer followed by\n",
    "# another convolution layer followed by another batchnorm layer. \n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, width_mult=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # layer initialization, mid_channels represents our output channels based on WeightSlice\n",
    "        mid_channels = int(out_channels * width_mult)\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = SubnetNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = SubnetNorm2d(out_channels)\n",
    "\n",
    "        # define downsampling function for shape matching\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39340751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated SuperNet. \n",
    "# We represent LayerSelect by choosing which BasicBlocks we want to be active.\n",
    "class MiniSuperNet(nn.Module):\n",
    "    def __init__(self, depth=3, width_mult=1.0):\n",
    "        super().__init__()\n",
    "        self.width_mult = width_mult\n",
    "        self.depth = depth        \n",
    "\n",
    "        # initial stem definition\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            SubnetNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # hardcoded 4 residual blocks that we will dynamically activate\n",
    "        self.blocks = nn.ModuleList()\n",
    "        in_out_channels = [(64, 64), (64, 128), (128, 128), (128, 256)]\n",
    "        for i, (in_c, out_c) in enumerate(in_out_channels):\n",
    "            block = BasicBlock(in_c, out_c, stride=2 if i > 0 else 1, width_mult=width_mult)\n",
    "            self.blocks.append(LayerSelect(block, active=(i < depth)))\n",
    "\n",
    "        # define pooling function\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "    # finds the SubnetNorm2d layer and sets the active config to the (config id) config\n",
    "    def set_active_config(self, config_id):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, SubnetNorm2d):\n",
    "                layer.set_active(config_id)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        if not hasattr(self, 'fc') or self.fc.in_features != x.shape[1]:\n",
    "            self.fc = nn.Linear(x.shape[1], 10).to(x.device)\n",
    "\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35accc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_stats(model, config_id, dataloader, device=\"cpu\", num_batches=20):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.set_active_config(config_id)\n",
    "\n",
    "    hooks = []\n",
    "    activations = {}\n",
    "\n",
    "    # Find SubnetNorm layers and register hooks on their corresponding conv layers\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, SubnetNorm2d):\n",
    "            activations[module] = []\n",
    "            \n",
    "            def make_hook(layer_ref):\n",
    "                def hook_fn(module, input, output):\n",
    "                    # Capture the raw conv output (input to SubnetNorm)\n",
    "                    activations[layer_ref].append(input[0].detach())\n",
    "                return hook_fn\n",
    "            \n",
    "            # Register hook on the SubnetNorm layer to capture its input\n",
    "            hooks.append(module.register_forward_hook(make_hook(module)))\n",
    "\n",
    "    # Run forward passes\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            _ = model(images)\n",
    "\n",
    "    # Clean up hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # Calculate statistics\n",
    "    for layer, xs in activations.items():\n",
    "        if len(xs) > 0:  # Safety check\n",
    "            all_x = torch.cat(xs, dim=0)\n",
    "            mean = all_x.mean(dim=(0, 2, 3))\n",
    "            var = all_x.var(dim=(0, 2, 3), unbiased=False)\n",
    "            layer.stats[config_id] = {\"mean\": mean, \"var\": var}\n",
    "            print(f\"Precomputed stats for {layer} with {len(xs)} batches\")\n",
    "        else:\n",
    "            print(f\"Warning: No activations captured for layer {layer} - likely inactive for this config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "135ea09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=10, device='cpu'):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            if i >= 200:  # More batches\n",
    "                break\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Track accuracy during training\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            train_acc = 100 * correct / total\n",
    "            print(f'Epoch {epoch}, Loss: {running_loss/200:.4f}, Train Acc: {train_acc:.1f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d02476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, dataloader, config_id, device='cpu', num_batches=20, measure_accuracy=False):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    model.set_active_config(config_id)\n",
    "\n",
    "    total_time = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Start timing\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            logits = model(images)\n",
    "\n",
    "            # Stop timing\n",
    "            end_time = time.perf_counter()\n",
    "            total_time += (end_time - start_time)\n",
    "\n",
    "            if measure_accuracy:\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "    avg_latency = total_time / (num_batches * images.size(0))  # time per sample\n",
    "\n",
    "    results = {\n",
    "        \"config_id\": config_id,\n",
    "        \"avg_latency_sec\": avg_latency\n",
    "    }\n",
    "\n",
    "    if measure_accuracy and total > 0:\n",
    "        results[\"accuracy\"] = correct / total\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8709fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard normalization and resizing for CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "full_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(full_train))\n",
    "precomp_size = len(full_train) - train_size\n",
    "train_dataset, precomp_dataset = random_split(full_train, [train_size, precomp_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "precomp_loader = DataLoader(precomp_dataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create different models for each config\n",
    "models = {\n",
    "    \"D1_W50\": MiniSuperNet(depth=1, width_mult=0.5),    \n",
    "    \"D2_W75\": MiniSuperNet(depth=2, width_mult=0.75), \n",
    "    \"D3_W100\": MiniSuperNet(depth=3, width_mult=1.0)\n",
    "}\n",
    "\n",
    "# Train each model using the training split\n",
    "for config_id, model in models.items():\n",
    "    print(f\"\\nTraining {config_id}...\")\n",
    "    train_model(model, train_loader, epochs=10, device=device)  # Use train_loader instead of cifar_loader\n",
    "    print(f\"Finished training {config_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75569eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Precomputed stats for SubnetNorm2d() with 10 batches\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n",
      "Warning: No activations captured for layer SubnetNorm2d() - likely inactive for this config\n"
     ]
    }
   ],
   "source": [
    "# Precompute stats for each model\n",
    "for config_id, model in models.items():\n",
    "    model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    precompute_stats(model, config_id, precomp_loader, num_batches=10)  # Use precomp_loader instead of cifar_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e01789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for benchmarking\n",
    "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())  # No augmentation for test\n",
    "test_loader = DataLoader(cifar_test, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark each model\n",
    "results = []\n",
    "for config_id, model in models.items():\n",
    "    res = benchmark_inference(model, test_loader, config_id=config_id, device=device, num_batches=20, measure_accuracy=True)\n",
    "    results.append(res)\n",
    "\n",
    "# Print nicely\n",
    "for r in results:\n",
    "    print(f\"{r['config_id']} → Latency: {r['avg_latency_sec']*1e3:.2f} ms/sample, Accuracy: {r.get('accuracy', 'N/A'):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperServe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
